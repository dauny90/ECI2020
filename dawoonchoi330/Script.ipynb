{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo librerias necesiaras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import pandas_profiling as pdf\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de datos para train y testing\n",
    "df_train = pd.read_csv('../data_input/Entrenamieto_ECI_2020.csv')\n",
    "df_test = pd.read_csv('../data_input/Validacion_ECI_2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reclasificacion de los valores\n",
    "df_train['Stage'] = df_train['Stage'].map({'Closed Lost': 0 , 'Closed Won' : 1,'Proposal': 0,'Negotiation': 0,'Qualification': 0})\n",
    "df_test['Stage'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unifico tanto train y testing para unificar crierios y optimizar codigo\n",
    "df = df_train.append(df_test,sort=False,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino columnas insignificantes\n",
    "df.drop(['ID','Actual_Delivery_Date','ASP_(converted)_Currency','Last_Activity','Prod_Category_A','Month','Total_Amount_Currency','Delivery_Year','Opportunity_Name'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convierto variables fechas a tipo de datos datetime de pandas\n",
    "df['Account_Created_Date'] = pd.to_datetime(df['Account_Created_Date'])\n",
    "df['Opportunity_Created_Date'] = pd.to_datetime(df['Opportunity_Created_Date'])\n",
    "df['Quote_Expiry_Date'] = pd.to_datetime(df['Quote_Expiry_Date'])\n",
    "df['Last_Modified_Date'] = pd.to_datetime(df['Last_Modified_Date'])\n",
    "df['Planned_Delivery_Start_Date'] = pd.to_datetime(df['Planned_Delivery_Start_Date'])\n",
    "df['Planned_Delivery_End_Date'] = pd.to_datetime(df['Planned_Delivery_End_Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Me creo una variable que cuente la cantidad de productos por oportunidad\n",
    "df_o = df.groupby('Opportunity_ID')['Opportunity_ID'].count()\n",
    "df_o.name = 'OpporCount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparo el conjunto de datos que es estatico de la oportunidad\n",
    "df_t_O = df.drop([\n",
    "'Product_Family',\n",
    "'Product_Name',\n",
    "'Planned_Delivery_Start_Date',\n",
    "'Planned_Delivery_End_Date',\n",
    "'Delivery_Quarter',\n",
    "'TRF',\n",
    "'Total_Amount',\n",
    "'ASP',\n",
    "'ASP_(converted)'],axis=1).drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrir las variables fechas por mes,dia,dayoffwee,qurter,weekofyear\n",
    "df_t_O['Account_Created_Date_month'] = pd.DatetimeIndex(df_t_O['Account_Created_Date']).month\n",
    "df_t_O['Account_Created_Date_day'] = pd.DatetimeIndex(df_t_O['Account_Created_Date']).day\n",
    "df_t_O['Account_Created_Date_dayofweek'] = df_t_O['Account_Created_Date'].dt.dayofweek\n",
    "df_t_O['Account_Created_Date_quarter'] = df_t_O['Account_Created_Date'].dt.quarter\n",
    "df_t_O['Account_Created_Date_weekofYear'] = df_t_O['Account_Created_Date'].dt.weekofyear\n",
    "df_t_O['Account_Created_Date_month_bimester'] = df_t_O['Account_Created_Date_month'].map({1:1,2:1 , 3:2,4:2 , 5:3,6:3 , 7:4,8:4 , 9:5,10:5 , 11:6,12:6})\n",
    "\n",
    "\n",
    "df_t_O['Last_Modified_Date_month'] = pd.DatetimeIndex(df_t_O['Last_Modified_Date']).month\n",
    "df_t_O['Last_Modified_Date_day'] = pd.DatetimeIndex(df_t_O['Last_Modified_Date']).day\n",
    "df_t_O['Last_Modified_Date_dayofweek'] = df_t_O['Last_Modified_Date'].dt.dayofweek\n",
    "df_t_O['Last_Modified_Date_quater'] = df_t_O['Last_Modified_Date'].dt.quarter\n",
    "df_t_O['Last_Modified_Date_weekofYear'] = df_t_O['Last_Modified_Date'].dt.weekofyear\n",
    "df_t_O['Last_Modified_Date_month_bimester'] = df_t_O['Last_Modified_Date_month'].map({1:1,2:1 , 3:2,4:2 , 5:3,6:3 , 7:4,8:4 , 9:5,10:5 , 11:6,12:6})\n",
    "\n",
    "df_t_O['Opportunity_Created_Date_month'] = pd.DatetimeIndex(df_t_O['Opportunity_Created_Date']).month\n",
    "df_t_O['Opportunity_Created_Date_day'] = pd.DatetimeIndex(df_t_O['Opportunity_Created_Date']).day\n",
    "df_t_O['Opportunity_Created_Date_dayofweek'] = df_t_O['Opportunity_Created_Date'].dt.dayofweek\n",
    "df_t_O['Opportunity_Created_Date_quater'] = df_t_O['Opportunity_Created_Date'].dt.quarter\n",
    "df_t_O['Opportunity_Created_Date_weekOfyear'] = df_t_O['Opportunity_Created_Date'].dt.weekofyear\n",
    "df_t_O['Opportunity_Created_Date_weekday'] = df_t_O['Opportunity_Created_Date'].dt.weekday\n",
    "df_t_O['Opportunity_Created_Date_bimester'] = df_t_O['Opportunity_Created_Date_month'].map({1:1,2:1 , 3:2,4:2 , 5:3,6:3 , 7:4,8:4 , 9:5,10:5 , 11:6,12:6})\n",
    "\n",
    "df_t_O['Quote_Expiry_Date_month'] = pd.DatetimeIndex(df_t_O['Quote_Expiry_Date']).month\n",
    "df_t_O['Quote_Expiry_Date_day'] = pd.DatetimeIndex(df_t_O['Quote_Expiry_Date']).day\n",
    "df_t_O['Quote_Expiry_Date_dayofweek'] = df_t_O['Quote_Expiry_Date'].dt.dayofweek\n",
    "df_t_O['Quote_Expiry_Date_quater'] = df_t_O['Quote_Expiry_Date'].dt.quarter\n",
    "df_t_O['Quote_Expiry_Date_weekofYear'] = df_t_O['Quote_Expiry_Date'].dt.weekofyear\n",
    "df_t_O['Quote_Expiry_Date_weekday'] = df_t_O['Quote_Expiry_Date'].dt.weekday\n",
    "df_t_O['Quote_Expiry_Date_bimester'] = df_t_O['Quote_Expiry_Date_month'].map({1:1,2:1 , 3:2,4:2 , 5:3,6:3 , 7:4,8:4 , 9:5,10:5 , 11:6,12:6})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo variables que representen diferencias de dias\n",
    "df_t_O['lastModified_AccountCreated_dif'] =  (df_t_O['Last_Modified_Date'] - df_t_O['Account_Created_Date']).dt.days \n",
    "df_t_O['opportuniy_AccountCreated_dif'] =  (df_t_O['Opportunity_Created_Date'] - df_t_O['Account_Created_Date']).dt.days\n",
    "df_t_O['lastModified_Oppor_dif'] =  (df_t_O['Last_Modified_Date'] - df_t_O['Opportunity_Created_Date']).dt.days \n",
    "df_t_O['Quote_Oppor_dif'] =  (df_t_O['Quote_Expiry_Date'] - df_t_O['Opportunity_Created_Date']).dt.days\n",
    "df_t_O['lastModified_Account_dif'] =  (df_t_O['Last_Modified_Date'] - df_t_O['Account_Created_Date']).dt.days\n",
    "df_t_O['Quote_lastModified_dif'] =  (df_t_O['Quote_Expiry_Date'] - df_t_O['Last_Modified_Date']).dt.days\n",
    "df_t_O.drop(list(df_t_O.select_dtypes(include=['datetime64[ns]']).columns.values),axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazo los valores no enteros por un default\n",
    "df_t_O['Sales_Contract_No'] = df_t_O['Sales_Contract_No'].replace(['None'], -1).astype(str).astype(int)\n",
    "df_t_O['Price'] = df_t_O['Price'].replace(['None'], -1)\n",
    "df_t_O['Price'] = df_t_O['Price'].replace(['Other'], -10).astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazo los valores no enteros por la media\n",
    "df_t_O['Sales_Contract_No_1'] = df_t_O['Sales_Contract_No'].replace(-1,df_t_O[df_t_O['Sales_Contract_No'] != -1]['Sales_Contract_No'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazo los valores no enteros por la media\n",
    "df_t_O['Price_1'] = df_t_O['Price'].replace([-1,-10],df_t_O[~df_t_O['Price'].isin([-1,-10])]['Price'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazo los valore no enteros por la media\n",
    "df_t_O['Price'] = df_t_O['Price'].replace(['None','Other'], -1 ).astype(str).astype(float)\n",
    "df_t_O['Price'] = df_t_O['Price'].replace(-1,df_t_O[df_t_O['Price'] != -1]['Price'].mean()).astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Un intento de crear mas variables por cada oportunidad, no mejora la performance\n",
    "\n",
    "# brand = df_t_O.groupby('Brand')['Opportunity_ID'].count()\n",
    "# brand.name = 'brand_name_j'\n",
    "\n",
    "# region = df_t_O.groupby('Region')['Opportunity_ID'].count()\n",
    "# region.name = 'region_name_j'\n",
    "\n",
    "# territorio = df_t_O.groupby('Territory')['Opportunity_ID'].count()\n",
    "# territorio.name = 'territorio_name_j'\n",
    "\n",
    "# account = df_t_O.groupby('Account_Name')['Opportunity_ID'].count()\n",
    "# account.name = 'account_name_j'\n",
    "\n",
    "# op_ow = df_t_O.groupby('Opportunity_Owner')['Opportunity_ID'].count()\n",
    "# op_ow.name = 'oppor_owner_j'\n",
    "\n",
    "# ac_ow = df_t_O.groupby('Account_Owner')['Opportunity_ID'].count()\n",
    "# ac_ow.name = 'account_owner_j'\n",
    "\n",
    "# df_t_O = pd.merge(df_t_O,\n",
    "#                  account,\n",
    "#                  on='Account_Name')\n",
    "\n",
    "# df_t_O = pd.merge(df_t_O,\n",
    "#                  op_ow,\n",
    "#                  on='Opportunity_Owner')\n",
    "\n",
    "# df_t_O = pd.merge(df_t_O,\n",
    "#                  brand,\n",
    "#                  on='Brand')\n",
    "\n",
    "# df_t_O = pd.merge(df_t_O,\n",
    "#                  region,\n",
    "#                  on='Region')\n",
    "\n",
    "# df_t_O = pd.merge(df_t_O,\n",
    "#                  territorio,\n",
    "#                  on='Territory')\n",
    "\n",
    "# df_t_O = pd.merge(df_t_O,\n",
    "#                  ac_ow,\n",
    "#                  on='Account_Owner')\n",
    "\n",
    "# monto = df_t_O.groupby('Account_Name')['Total_Taxable_Amount','Price'].agg([np.min, np.max, np.mean,np.median,np.sum])\n",
    "\n",
    "# monto.columns = ['_'.join(col) for col in monto.columns]\n",
    "\n",
    "# df_t_O = pd.merge(df_t_O,\n",
    "#                  monto,\n",
    "#                  on='Account_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo valores dummys\n",
    "for col in list(df_t_O.select_dtypes(include=['object']).columns.values):\n",
    "           df_t_O  = pd.concat([df_t_O,pd.get_dummies(df_t_O[col],prefix=[col],drop_first=True,dummy_na=True)], axis=1) \n",
    "df_t_O.drop(list(df_t_O.select_dtypes(include=['object']).columns.values),axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparo el conjunto de variables que describen a los productos de la oportunidad\n",
    "df_t_g = df[[\n",
    "'Opportunity_ID',\n",
    "'Product_Family',\n",
    "'Product_Name',\n",
    "'Planned_Delivery_Start_Date',\n",
    "'Planned_Delivery_End_Date',\n",
    "'Account_Created_Date',\n",
    "'Delivery_Quarter',\n",
    "'TRF',\n",
    "'Total_Amount',\n",
    "'ASP',\n",
    "'Price',\n",
    "'Total_Taxable_Amount',\n",
    "'ASP_(converted)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de nuevas variables de fechas\n",
    "\n",
    "df_t_g['Planned_Delivery_Start_Date_month'] = pd.DatetimeIndex(df_t_g['Planned_Delivery_Start_Date']).month\n",
    "df_t_g['Planned_Delivery_End_Date_month'] = pd.DatetimeIndex(df_t_g['Planned_Delivery_End_Date']).month\n",
    "\n",
    "df_t_g['Planned_Delivery_Start_Date_day'] = pd.DatetimeIndex(df_t_g['Planned_Delivery_Start_Date']).day\n",
    "df_t_g['Planned_Delivery_End_Date_day'] = pd.DatetimeIndex(df_t_g['Planned_Delivery_End_Date']).day\n",
    "\n",
    "df_t_g['Planned_Delivery_Start_Date_dayofweek'] = df_t_g['Planned_Delivery_Start_Date'].dt.dayofweek\n",
    "df_t_g['Planned_Delivery_End_Date_dayofweek'] = df_t_g['Planned_Delivery_End_Date'].dt.dayofweek\n",
    "\n",
    "df_t_g['Planned_Delivery_Start_Date_quater'] = df_t_g['Planned_Delivery_Start_Date'].dt.quarter\n",
    "df_t_g['Planned_Delivery_End_Date_quater'] = df_t_g['Planned_Delivery_End_Date'].dt.quarter\n",
    "\n",
    "df_t_g['Planned_Delivery_Start_Date_weekday'] = df_t_g['Planned_Delivery_Start_Date'].dt.weekday\n",
    "df_t_g['Planned_Delivery_End_Date_weekday'] = df_t_g['Planned_Delivery_End_Date'].dt.weekday\n",
    "\n",
    "df_t_g['Planned_Delivery_Start_Date_weekofYear'] = df_t_g['Planned_Delivery_Start_Date'].dt.weekofyear\n",
    "df_t_g['Planned_Delivery_End_Date_weekofYear'] = df_t_g['Planned_Delivery_End_Date'].dt.weekofyear\n",
    "\n",
    "df_t_g['Planned_Delivery_Start_Date_bimester'] = df_t_g['Planned_Delivery_Start_Date_month'].map({1:1,2:1 , 3:2,4:2 , 5:3,6:3 , 7:4,8:4 , 9:5,10:5 , 11:6,12:6})\n",
    "df_t_g['Planned_Delivery_End_Date_bimester'] = df_t_g['Planned_Delivery_End_Date_month'].map({1:1,2:1 , 3:2,4:2 , 5:3,6:3 , 7:4,8:4 , 9:5,10:5 , 11:6,12:6})\n",
    "\n",
    "\n",
    "df_t_g['Planned_Delivery_diferencia'] =  (df_t_g['Planned_Delivery_End_Date'] - df_t_g['Planned_Delivery_Start_Date']).dt.days \n",
    "df_t_g['end_account_diferencia'] =  (df_t_g['Planned_Delivery_End_Date'] - df_t_g['Account_Created_Date']).dt.days\n",
    "df_t_g['start_account_diferencia'] =  (df_t_g['Planned_Delivery_Start_Date'] - df_t_g['Account_Created_Date']).dt.days\n",
    "\n",
    "\n",
    "df_t_g.drop(['Planned_Delivery_Start_Date','Planned_Delivery_End_Date','Account_Created_Date'],axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupo las variables numericas y creo algunas medidas\n",
    "\n",
    "df_t_g_f = df_t_g[['Planned_Delivery_Start_Date_month',\n",
    "'Planned_Delivery_End_Date_month',\n",
    "'Planned_Delivery_Start_Date_day',\n",
    "'Planned_Delivery_End_Date_day',\n",
    "'Planned_Delivery_Start_Date_dayofweek',\n",
    "'Planned_Delivery_End_Date_dayofweek',\n",
    "'Planned_Delivery_Start_Date_quater',\n",
    "'Planned_Delivery_End_Date_quater',\n",
    "'Planned_Delivery_End_Date_weekday',\n",
    "'Planned_Delivery_Start_Date_weekday',\n",
    "'Planned_Delivery_Start_Date_weekofYear',\n",
    "'Planned_Delivery_End_Date_weekofYear',\n",
    "'Planned_Delivery_End_Date_bimester',\n",
    "'Planned_Delivery_Start_Date_bimester',\n",
    "'Planned_Delivery_diferencia',\n",
    "'end_account_diferencia',\n",
    "'start_account_diferencia',\n",
    "'Opportunity_ID']\n",
    "].groupby('Opportunity_ID').agg([np.min, np.max, np.mean,np.median,np.sum,])\n",
    "df_t_g_f.columns = ['_'.join(col) for col in df_t_g_f.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupo las variables numericas y creo algunas medidas\n",
    "\n",
    "#fechas = list(df_train.select_dtypes(include=['datetime64[ns]']).columns.values)\n",
    "df_t_g = df_t_g[['TRF','Total_Amount','ASP','ASP_(converted)','Price','Total_Taxable_Amount','Opportunity_ID']].groupby('Opportunity_ID').agg([np.min, np.max, np.mean,np.median,np.sum])\n",
    "df_t_g.columns = ['_'.join(col) for col in df_t_g.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo dummies a partir de la variable product family\n",
    "pf = pd.concat([df['Opportunity_ID'],pd.get_dummies(df['Product_Family'],prefix=['PF_A'],drop_first=True,dummy_na=True)], axis=1)\n",
    "pf = pf.groupby('Opportunity_ID').agg(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo dummies a partir de la variable product name\n",
    "pn = pd.concat([df['Opportunity_ID'],pd.get_dummies(df['Product_Name'],prefix=['PN_A'],drop_first=True,dummy_na=True)], axis=1)\n",
    "pn = pn.groupby('Opportunity_ID').agg(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo dummies a partir de la variable Deivery Quarter\n",
    "dq = pd.concat([df['Opportunity_ID'],pd.get_dummies(df['Delivery_Quarter'],prefix=['DQ_A'],drop_first=True,dummy_na=True)], axis=1)\n",
    "dq = dq.groupby('Opportunity_ID').agg(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concateno todos los sets y unifico\n",
    "df_t_G = pd.concat([df_t_g,pf,pn,dq,df_t_g_f],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t_G.reset_index(drop=True, inplace=True)\n",
    "df_t_O.reset_index(drop=True, inplace=True)\n",
    "df_o.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estructura final de datos\n",
    "df_final = pd.concat([df_t_G, df_t_O,df_o], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino variables independientes correlacionadas\n",
    "c = df_final.corr().abs()\n",
    "#s = c.unstack()\n",
    "\n",
    "upper = c.where(np.triu(np.ones(c.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "df_final.drop(df_final[to_drop], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('../data_processed/df_final.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train = df_final[df_final['Stage'] != -1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_test = df_final[df_final['Stage'] == -1 ]\n",
    "df_final_test.drop('Stage',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import itertools\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_final_train['Stage']\n",
    "X = df_final_train.drop('Stage',axis=1)\n",
    "#X = df_final_train.drop(['Stage','Opportunity_ID'],axis=1)\n",
    "#ido = df_final_train['Opportunity_ID']\n",
    "X.columns = np.arange(X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_grid(data_dict):\n",
    "  rows = itertools.product(*data_dict.values())\n",
    "  return pd.DataFrame.from_records(rows, columns=data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_data = lgb.Dataset(X, label = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm parameters\n",
    "parameters = {\n",
    "    'max_depth': np.arange(13,14,1),\n",
    "    'feature_fraction': np.arange(0.2,0.22,0.005),\n",
    "    'bagging_fraction': np.arange(0.9,0.95,0.005),\n",
    "    'lambda': np.arange(0.2,0.3,0.005),\n",
    "    'application': ['binary'],\n",
    "    'boosting': ['gbdt'],\n",
    "    #'num_boost_round' : np.arange(100,1000,100),\n",
    "    'learning_rate': np.arange(0.1,0.2,0.005),\n",
    "    'objective': ['binary'],\n",
    "    'metric': ['binary_logloss'],\n",
    "    'is_unbalance': ['false'],\n",
    "    'num_leaves': np.arange(18,20,1),\n",
    "    'bagging_freq': np.arange(16,18,1),\n",
    "    'num_boost_round': np.arange(1900,2020,10)\n",
    "    #'verbose': [0]    \n",
    "}\n",
    "\n",
    "parametersdf = expand_grid(parameters).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parametersdf.drop('num_boost_round',axis=1).iloc[i].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = []\n",
    "for i in range(len(parametersdf)):  \n",
    "  modelo = lgb.cv(parametersdf.drop('num_boost_round',axis=1).iloc[i].to_dict(), cv_data, nfold=5,early_stopping_rounds = 20,num_boost_round=parametersdf.iloc[i].to_dict()['num_boost_round'])\n",
    "  print(min(modelo['binary_logloss-mean']))\n",
    "  #print(int(np.argmin(modelo['binary_logloss-mean']) + 1))\n",
    "  #print(i)\n",
    "  auc.append([min(modelo['binary_logloss-mean']),int(np.argmin(modelo['binary_logloss-mean']) + 1),i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = pd.DataFrame(auc,columns=['auc','it','loc'])\n",
    "resultado[resultado['auc'] == resultado['auc'].min()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametersdf.iloc[resultado[resultado['auc'] == resultado['auc'].min()]['loc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = parametersdf.iloc[resultado[resultado['auc'] == resultado['auc'].min()]['loc']]\n",
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting': 'gbdt',\n",
    "    'max_depth' : np.array(params['max_depth']).item(),\n",
    "    'lambda' : np.array(params['lambda']).item(),\n",
    "    'num_leaves': np.array(params['num_leaves']).item(),\n",
    "    'feature_fraction': np.array(params['feature_fraction']).item(),\n",
    "    'bagging_fraction': np.array(params['bagging_fraction']).item(),\n",
    "    'bagging_freq': np.array(params['bagging_freq']).item(),\n",
    "    'learning_rate': np.array(params['learning_rate']).item(),\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.train(parameters,\n",
    "                       cv_data,\n",
    "                       #valid_sets=lgb_eval,\n",
    "                       num_boost_round=resultado[resultado['auc'] == resultado['auc'].min()]['it'].item(),\n",
    "                       #early_stopping_rounds=100\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(df_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id': df_final_test['Opportunity_ID'], 'target': pred})\n",
    "output.sort_values(by=['id'],inplace=True)\n",
    "output.to_csv('../results/'+str(resultado[resultado['auc'] == resultado['auc'].min()]['auc'].item()) + '.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import log_metric, log_param, log_artifact , create_experiment ,get_experiment_by_name ,start_run ,end_run ,set_experiment\n",
    "import mlflow.sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametrs = {'application': 'binary',\n",
    " 'bagging_fraction': 0.9500000000000002,\n",
    " 'bagging_freq': 16,\n",
    " 'boosting': 'gbdt',\n",
    " 'feature_fraction': 0.2,\n",
    " 'lambda': 0.1,\n",
    " 'learning_rate': 0.1,\n",
    " 'max_depth': 12,\n",
    " 'metric': 'binary_logloss',\n",
    " 'num_leaves': 19,\n",
    " 'objective': 'binary',\n",
    " 'verbose': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expermientName = 'Competencia_AlixPartner_Oportunidad_compras'\n",
    "\n",
    "try:\n",
    "    experiment_id = create_experiment(name=expermientName)\n",
    "except:\n",
    "    experiment_id = get_experiment_by_name(name=expermientName).experiment_id\n",
    "\n",
    "set_experiment(expermientName)\n",
    "with start_run():\n",
    "    log_param(\"parameters\",parameters)\n",
    "    log_metric(\"logloss\",resultado[resultado['auc'] == resultado['auc'].min()]['auc'].item())\n",
    "    log_artifact('../data_processed/df_final.csv')\n",
    "    #log_artifact('../results/'+str(resultado[resultado['auc'] == resultado['auc'].min()]['auc'].item()) + '.csv')\n",
    "    log_artifact('../results/0.07738.csv')\n",
    "    log_artifact('Script_1.ipynb')\n",
    "    #mlflow.sklearn.save_model(model,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOP5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5 = resultado.sort_values('auc').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = parametersdf.iloc[int(top5.iloc[0]['loc'])]\n",
    "parameters1 = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting': 'gbdt',\n",
    "    'max_depth' : np.array(params1['max_depth']).item(),\n",
    "    'lambda' : np.array(params1['lambda']).item(),\n",
    "    'num_leaves': np.array(params1['num_leaves']).item(),\n",
    "    'feature_fraction': np.array(params1['feature_fraction']).item(),\n",
    "    'bagging_fraction': np.array(params1['bagging_fraction']).item(),\n",
    "    'bagging_freq': np.array(params1['bagging_freq']).item(),\n",
    "    'learning_rate': np.array(params1['learning_rate']).item(),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "params2 = parametersdf.iloc[int(top5.iloc[1]['loc'])]\n",
    "parameters2 = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting': 'gbdt',\n",
    "    'max_depth' : np.array(params2['max_depth']).item(),\n",
    "    'lambda' : np.array(params2['lambda']).item(),\n",
    "    'num_leaves': np.array(params2['num_leaves']).item(),\n",
    "    'feature_fraction': np.array(params2['feature_fraction']).item(),\n",
    "    'bagging_fraction': np.array(params2['bagging_fraction']).item(),\n",
    "    'bagging_freq': np.array(params2['bagging_freq']).item(),\n",
    "    'learning_rate': np.array(params2['learning_rate']).item(),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "params3 = parametersdf.iloc[int(top5.iloc[2]['loc'])]\n",
    "parameters3 = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting': 'gbdt',\n",
    "    'max_depth' : np.array(params3['max_depth']).item(),\n",
    "    'lambda' : np.array(params3['lambda']).item(),\n",
    "    'num_leaves': np.array(params3['num_leaves']).item(),\n",
    "    'feature_fraction': np.array(params3['feature_fraction']).item(),\n",
    "    'bagging_fraction': np.array(params3['bagging_fraction']).item(),\n",
    "    'bagging_freq': np.array(params3['bagging_freq']).item(),\n",
    "    'learning_rate': np.array(params3['learning_rate']).item(),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "params4 = parametersdf.iloc[int(top5.iloc[3]['loc'])]\n",
    "parameters4 = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting': 'gbdt',\n",
    "    'max_depth' : np.array(params4['max_depth']).item(),\n",
    "    'lambda' : np.array(params4['lambda']).item(),\n",
    "    'num_leaves': np.array(params4['num_leaves']).item(),\n",
    "    'feature_fraction': np.array(params4['feature_fraction']).item(),\n",
    "    'bagging_fraction': np.array(params4['bagging_fraction']).item(),\n",
    "    'bagging_freq': np.array(params4['bagging_freq']).item(),\n",
    "    'learning_rate': np.array(params4['learning_rate']).item(),\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "params5 = parametersdf.iloc[int(top5.iloc[4]['loc'])]\n",
    "parameters5 = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'boosting': 'gbdt',\n",
    "    'max_depth' : np.array(params5['max_depth']).item(),\n",
    "    'lambda' : np.array(params5['lambda']).item(),\n",
    "    'num_leaves': np.array(params5['num_leaves']).item(),\n",
    "    'feature_fraction': np.array(params5['feature_fraction']).item(),\n",
    "    'bagging_fraction': np.array(params5['bagging_fraction']).item(),\n",
    "    'bagging_freq': np.array(params5['bagging_freq']).item(),\n",
    "    'learning_rate': np.array(params5['learning_rate']).item(),\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = lgb.train(parameters1,\n",
    "                       cv_data,\n",
    "                       #valid_sets=lgb_eval,\n",
    "                       num_boost_round=int(resultado.sort_values('auc').iloc[0]['it'].item())\n",
    "                       #early_stopping_rounds=100\n",
    "                      )\n",
    "\n",
    "model2 = lgb.train(parameters2,\n",
    "                       cv_data,\n",
    "                       #valid_sets=lgb_eval,\n",
    "                       num_boost_round=int(resultado.sort_values('auc').iloc[1]['it'].item())\n",
    "                       #early_stopping_rounds=100\n",
    "                      )\n",
    "\n",
    "model3 = lgb.train(parameters3,\n",
    "                       cv_data,\n",
    "                       #valid_sets=lgb_eval,\n",
    "                       num_boost_round=int(resultado.sort_values('auc').iloc[2]['it'].item())\n",
    "                       #early_stopping_rounds=100\n",
    "                      )\n",
    "\n",
    "model4 = lgb.train(parameters4,\n",
    "                       cv_data,\n",
    "                       #valid_sets=lgb_eval,\n",
    "                       num_boost_round=int(resultado.sort_values('auc').iloc[3]['it'].item())\n",
    "                       #early_stopping_rounds=100\n",
    "                      )\n",
    "\n",
    "model5 = lgb.train(parameters5,\n",
    "                       cv_data,\n",
    "                       #valid_sets=lgb_eval,\n",
    "                       num_boost_round=int(resultado.sort_values('auc').iloc[4]['it'].item())\n",
    "                       #early_stopping_rounds=100\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict(df_final_test)\n",
    "pred2 = model2.predict(df_final_test)\n",
    "pred3 = model3.predict(df_final_test)\n",
    "pred4 = model4.predict(df_final_test)\n",
    "pred5 = model5.predict(df_final_test)\n",
    "\n",
    "output = pd.DataFrame({'id': df_final_test['Opportunity_ID'], 'target': (pred1+pred2+pred3+pred4+pred5)/5})\n",
    "output.sort_values(by=['id'],inplace=True)\n",
    "output.to_csv('vote5.csv', index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
